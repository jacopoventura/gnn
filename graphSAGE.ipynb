{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1da7bd63",
   "metadata": {},
   "source": [
    "## Node embedding\n",
    "\n",
    "Source: https://towardsdatascience.com/node-embeddings-for-beginners-554ab1625d98\n",
    "\n",
    "Machine Learning algos **need some sort of vector input to be executed**. \n",
    "Since a network consists of connected nodes (with attributes), we need to use **node embedding to represent nodes as vectros**.\n",
    "\n",
    "Approaches for node embedding can also work for **graph or edge embedding**.\n",
    "\n",
    "### Classical ML approaches\n",
    "\n",
    "#### Linear regression\n",
    "\n",
    "Learn slope and intercept that model the linear relationship between the **ordered feature vector** and the class.\n",
    "\n",
    "![image](images/linear_regression.png)\n",
    "\n",
    "#### CNN\n",
    "\n",
    "Used for image classification. An image is a an **ordered matrix with pixel values (features)**. Layers of convolution (image processing) extract features from the image and a fully connected layer generates the final output.\n",
    "\n",
    "![image](images/cnn.png)\n",
    "\n",
    "#### RNN\n",
    "\n",
    "The input data are, for example, measurements from a time series, thus odered data.\n",
    "\n",
    "### Issue with graphs and node embeddings\n",
    "\n",
    "Unlike input data for classical Machine Learning, graphs do not have ordering (first/last nodes, top/bottom, left/right).\n",
    "\n",
    "Still, we need a procedure that returns a vector, either for a graph, a node or an edge. \n",
    "\n",
    "Finding a vector for a node is possible with node representation learning. The result of such representation learning is a node embedding (and so does graph embedding, edge embedding exist). \n",
    "\n",
    "*Embeddings should capture the graph topology, relationships between nodes and further relevant information*. **How the embeddings should capture this inherent information of the graph is not fixed. It depends on the questions we ask about the network.**\n",
    "\n",
    "![image](images/embedding_concept.png)\n",
    "\n",
    "Examples of node embedding are:\n",
    "1. node2vec\n",
    "2. deepwalk\n",
    "\n",
    "Node embedding must be learned (**unsupervised**) during the training. The initialization of the *d*-space of the embedded nodes is random.\n",
    "1. decide how large is the embedding space\n",
    "2. randomly initialize embeddings for each node/graph/edge\n",
    "3. learning the embeddings by repeatedly incrementally improve the embeddings such that it reflects the similarity in the network (loop)\n",
    "\n",
    "**Once embedding is known, we apply standard ML algos**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7213181b",
   "metadata": {},
   "source": [
    "### GraphSAGE\n",
    "\n",
    "Source: https://medium.com/analytics-vidhya/ohmygraphs-graphsage-and-inductive-representation-learning-ea26d2835331\n",
    "\n",
    "Source: https://medium.com/analytics-vidhya/ohmygraphs-graphsage-in-pyg-598b5ec77e7b\n",
    "\n",
    "GraphSAGE is an iterative algorithm that learns graph embeddings for every node in a certain graph. The novelty of GraphSAGE is that it was the first work to create inductive node embeddings in an unsupervised manner! (Prior to GraphSAGE, most node embedding models were based on spectral decomposition/matrix factorization methods.)\n",
    "\n",
    "**goal**: The goal of GraphSAGE is to learn a representation for every node based on some combination of its neighbouring nodes, parametrized by **h**.\n",
    "\n",
    "Let:\n",
    "\n",
    "- **x**_v: feature vector of the node *v*.\n",
    "- *k*: depth (how many layers of neighbor nodes are considered to update each node *v*)\n",
    "- **h**^k_v: embedded representation of the node *v* at the *k*-th iteration.\n",
    "- **z**_v: final embedding of the node *v*.\n",
    "\n",
    "![image](images/sage.png)\n",
    "\n",
    "Given a target node *v*, a layer works as follow:\n",
    "1. **node embedding** of all the nodes *u* connected to the target node *v*. This results into a list of embedded nodes **h**^k_u\n",
    "2. **aggregate** all the embedded nodes **h**^k_u into the node representation (embedded) **a**^k_v. The aggregate function must be differentiable, and it could be as simples as an averaging function or as complex as a neural network.\n",
    "3. **update** the node representation **h**^(k+1)_v using the aggregated representation **a**^k_v and the embedded neighbors **h**^k_u. The update function must be differentiable, and it could be as simples as an averaging function or as complex as a neural network.\n",
    "\n",
    "\n",
    "## graphSAGE \n",
    "\n",
    "Sample implementation with PyTorch:\n",
    "- small graph: PyTorchGeometry\n",
    "- large graph: Deep Graph Library\n",
    "\n",
    "\n",
    "**Graph convolution**: change the feature space of every node in the graph, but the graph structure does not change. In the picture, the convolution \"transforms\" the node features from a 4d vector to a 3d vector.\n",
    "\n",
    "![image](images/graph_convolution.png)\n",
    "\n",
    "\n",
    "The GraphSAGE model is simply a bunch of stacked SAGEConv layers on top of each other. The below model has 3 layers of convolutions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b6cac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import SAGEConv\n",
    "import torch\n",
    "\n",
    "\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, dropout=0.2):\n",
    "        \"\"\"\n",
    "        In the __init__, we list the functions of the layers that will be used to create the NN in the forward.\"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # Dropout: machine learning technique where you remove (or \"drop out\") \n",
    "        # units in a neural net to simulate training large numbers of architectures simultaneously. \n",
    "        # Importantly, dropout can drastically reduce the chance of overfitting during training.\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # define 3 layers of convolution of graghSAGE\n",
    "        # these are only functions to be learned in the training and shall be saved as internal variable\n",
    "        self.conv1 = SAGEConv(in_dim, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = SAGEConv(hidden_dim, out_dim)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        Forward propagation: the calculation process as the output layers values from the input data.\n",
    "        In the forward method, we create the actual NN to be trained.\n",
    "        \"\"\"\n",
    "        \n",
    "        x = self.conv1(data.x, data.adj_t)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=self.dropout)\n",
    "        \n",
    "        x = self.conv2(x, data.adj_t)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=self.dropout)\n",
    "        \n",
    "        x = self.conv3(x, data.adj_t)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=self.dropout)\n",
    "        return torch.log_softmax(x, dim=-1)\n",
    "    \n",
    "    def train(model, data, train_idx, optimizer):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)[train_idx]\n",
    "        loss = F.nll_loss(out, data.y.squeeze(1)[train_idx])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        return loss.item()\n",
    "    @torch.no_grad()\n",
    "    def test(model, data, split_idx, evaluator):\n",
    "        model.eval()\n",
    "        out = model(data)\n",
    "        y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "        train_acc = evaluator.eval({\n",
    "            'y_true': data.y[split_idx['train']],\n",
    "            'y_pred': y_pred[split_idx['train']],\n",
    "        })['acc']\n",
    "        valid_acc = evaluator.eval({\n",
    "            'y_true': data.y[split_idx['valid']],\n",
    "            'y_pred': y_pred[split_idx['valid']],\n",
    "        })['acc']\n",
    "        test_acc = evaluator.eval({\n",
    "            'y_true': data.y[split_idx['test']],\n",
    "            'y_pred': y_pred[split_idx['test']],\n",
    "        })['acc']\n",
    "        return train_acc, valid_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b930339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "\n",
    "device = f'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device)\n",
    "dataset = PygNodePropPredDataset(name='ogbn-products',\n",
    "                                 transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "# this dataset comes with train-val-test splits predefined for benchmarking\n",
    "split_idx = dataset.get_idx_split()\n",
    "train_idx = split_idx['train'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "454439b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dataset has 2449029 nodes where each node has a 100 dim feature vector\n",
      " dataset has 123718280 edges where each edge has a 0 dim feature vector\n",
      " dataset has 47 classes\n",
      "torch.Size([196615])\n",
      "torch.Size([39323])\n",
      "torch.Size([2213091])\n"
     ]
    }
   ],
   "source": [
    "print(f' dataset has {data.num_nodes} nodes where each node has a {data.num_node_features} dim feature vector')\n",
    "print(f' dataset has {data.num_edges} edges where each edge has a {data.num_edge_features} dim feature vector')\n",
    "print(f' dataset has {dataset.num_classes} classes')\n",
    "print(split_idx['train'].shape)\n",
    "print(split_idx['valid'].shape)\n",
    "print(split_idx['test'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74af49b",
   "metadata": {},
   "source": [
    "since we need to train on a certain set of nodes and validate/test on another set of nodes, we just mask out the gradients we want with the indexes of the nodes in our train/val/test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1d868e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# compute activations for train subset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m(data)[train_idx]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# get gradients for train subset\u001b[39;00m\n\u001b[1;32m      4\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnll_loss(out, data\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)[train_idx])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# compute activations for train subset\n",
    "out = model(data)[train_idx]\n",
    "# get gradients for train subset\n",
    "loss = F.nll_loss(out, data.y.squeeze(1)[train_idx])\n",
    "# evaluate model on test set\n",
    "out = model(data)[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dc7776",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
