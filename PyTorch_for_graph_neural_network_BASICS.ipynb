{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1fa62bc",
   "metadata": {},
   "source": [
    "# PART I: data as PyG Dataset\n",
    "\n",
    "Source: https://pytorch-geometric.readthedocs.io/en/latest/tutorial/create_dataset.html\n",
    "\n",
    "Example of saving a graph as Dataset: https://medium.com/cj-express-tech-tildi/first-timers-guide-to-pytorch-geometric-part-1-the-basic-1b6006e1f4db\n",
    "\n",
    "We can transform a graph into a PyG Datasets in order to automatically load raw data, process and save the graph in PyG format, which will be later loaded and fed into the DataLoader for the NN. (See Remark section: saving as dataset is not a mandatory step.)\n",
    "\n",
    "Two abstract classes are available for datasets:\n",
    "- and torch_geometric.data.InMemoryDataset: inherits from torch_geometric.data.Dataset and should be used if the whole dataset **fits into CPU memory (smaller dataset)**\n",
    "- torch_geometric.data.Dataset: to be used if data do **not fit into CPU memory (large dataset)**\n",
    "\n",
    "According to the size of the data, a class that inherits from either InMemoryDataset or from Dataset shall be implemented with some functions (virtual in the base class).\n",
    "\n",
    "### InMemoryDataset (small dataset)\n",
    "\n",
    "The dataset class must inherit from torch_geometric.data.InMemoryDataset and the following methods must be implemented:\n",
    "- *raw_file_names()*: list of files in the raw_dir which needs to be found in order to skip the download. This file stores the data in raw format, which requires processing and storage in the processed_file_names.\n",
    "- *processed_file_names()*: list of files in the processed_dir which needs to be found in order to skip the processing. This file stores the processed data (ideally ready for the Machine Learning model).\n",
    "- *download()*: downloads raw data into raw_dir.\n",
    "- *process()*: processes the raw data and saves it into the processed_dir. This is the **most important function to implement**.\n",
    "\n",
    "Furthermore, the init class can receive the following arguments (**None by default**), to be passed to the super().___init__():\n",
    "- transform: dynamically transforms the data object before accessing (so it is best used for data augmentation)\n",
    "- pre_transform: applies the transformation before saving the data objects to disk (so it is best used for heavy precomputation which needs to be only done once)\n",
    "- pre_filter: manually filters out data objects before saving.\n",
    "\n",
    "One unique characteristic of InMemoryDataset is the call of **collate()**: this functions transforms a Python list of Data or HeteroData objects <u>to the internal graph data storage format of InMemoryDataset</u>. This object is *data*, who cna be used with *slices* to reconstruc single examples of this object.\n",
    "Saving a huge dataset file is time consuming. \n",
    "\n",
    "Instead of saving the data structure directly, pytorch geometric separated data and a dictionary to reconstruct the dataset as:\n",
    "\n",
    "<code>data, slices = self.collate(data_list)</code>\n",
    "\n",
    "then saves the dataset with \n",
    "\n",
    "<code>torch.save((data, slices), self.processed_paths[0])</code>.\n",
    "\n",
    "Furthermore, we need to load these two objects in the constructor into the properties self.data and self.slices with the *standard line of code*:\n",
    "<code>self.data, self.slices = torch.load(self.processed_paths[0])</code>.\n",
    "\n",
    "The library torch_geometric.data provides some tools for downloading data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ae5aa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset, download_url\n",
    "\n",
    "\n",
    "class MyOwnInMemoryDataset(InMemoryDataset):\n",
    "    # init: here the transform, pre_transform and pre_filter functions can be passed\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "        \n",
    "        # super() function to inherit methods from the base class\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['some_file_1', 'some_file_2', ...]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    def download(self):\n",
    "        # Download to `self.raw_dir`.\n",
    "        download_url(url, self.raw_dir)\n",
    "        ...\n",
    "\n",
    "    def process(self):\n",
    "        # Read data into huge `Data` list.\n",
    "        data_list = [...]\n",
    "\n",
    "        # process the data\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        # collate and save data\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336dc85c",
   "metadata": {},
   "source": [
    "### Dataset (large dataset)\n",
    "\n",
    "If the dataset does not fit the CPU memory, then the class **torch_geometric.data.Dataset** shall be used as **base class**. In addition to <code>raw_file_names()</code>, <code>processed_file_names()</code>, <code>download()</code> and <code>process()</code>, the methods <code>len()</code> (returns the size of the dataset) and <code>get()</code> (logic to load a single graph, requires an index to access it) shall be implemented.\n",
    "\n",
    "Unlike InMemoryDataset, **collate() is not used**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fee9dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Dataset, download_url\n",
    "\n",
    "\n",
    "class MyOwnDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['some_file_1', 'some_file_2', ...]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data_1.pt', 'data_2.pt', ...]\n",
    "\n",
    "    def download(self):\n",
    "        # Download to `self.raw_dir`.\n",
    "        path = download_url(url, self.raw_dir)\n",
    "        ...\n",
    "\n",
    "    def process(self):\n",
    "        idx = 0\n",
    "        for raw_path in self.raw_paths:\n",
    "            # Read data from `raw_path`.\n",
    "            data = Data(...)\n",
    "\n",
    "            if self.pre_filter is not None and not self.pre_filter(data):\n",
    "                continue\n",
    "\n",
    "            if self.pre_transform is not None:\n",
    "                data = self.pre_transform(data)\n",
    "\n",
    "            torch.save(data, osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "            idx += 1\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d62857a",
   "metadata": {},
   "source": [
    "## Remarks on PyG Dataset\n",
    "\n",
    "#### Usage of PyG's <code>Dataset</code> is not mandatory\n",
    "We use PyG's Dataset only to process and save the dataset into a file. If we don't need to save the dataset on the disk, then we can directly pass the data into the <code>Dataloader</code> to interface with the Machine Learning model like:\n",
    "\n",
    "<code>\n",
    "    from torch_geometric.data import Data\n",
    "    from torch_geometric.loader import DataLoader\n",
    "    data_list = [Data(...), ..., Data(...)]\n",
    "    loader = DataLoader(data_list, batch_size=32)\n",
    "</code>\n",
    "\n",
    "#### Execution of download() / process() can be skipped by not implementing these functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a5846a",
   "metadata": {},
   "source": [
    "# Part II: GNN\n",
    "\n",
    "Source: https://pytorch-geometric.readthedocs.io/en/latest/tutorial/create_gnn.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d631069",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
